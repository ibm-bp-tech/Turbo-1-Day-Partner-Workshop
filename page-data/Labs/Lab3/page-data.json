{
    "componentChunkName": "component---src-pages-labs-lab-3-mdx",
    "path": "/Labs/Lab3/",
    "result": {"pageContext":{"frontmatter":{"0":"e","1":"x","2":"p","3":"o","4":"r","5":"t","6":" ","7":"c","8":"o","9":"n","10":"s","11":"t","12":" ","13":"T","14":"i","15":"t","16":"l","17":"e","18":" ","19":"=","20":" ","21":"(","22":")","23":" ","24":"=","25":">","26":" ","27":"(","28":" ","29":"<","30":"s","31":"p","32":"a","33":"n","34":">","35":" ","36":"L","37":"a","38":"b","39":" ","40":"3","41":" ","42":"-","43":" ","44":"P","45":"e","46":"r","47":"f","48":"o","49":"r","50":"m","51":"a","52":"n","53":"c","54":"e","55":" ","56":"R","57":"e","58":"c","59":"o","60":"m","61":"m","62":"e","63":"n","64":"d","65":"a","66":"t","67":"i","68":"o","69":"n","70":"s","71":" ","72":"<","73":"b","74":"r","75":" ","76":"/","77":">","78":" ","79":"<","80":"/","81":"s","82":"p","83":"a","84":"n","85":">","86":" ","87":")","88":";","description":"Labs / Lab 3","title":"Labs / Lab 3"},"relativePagePath":"/Labs/Lab3.mdx","titleType":"page","MdxNode":{"id":"c9281f15-e299-593a-8b94-ade39194598c","children":[],"parent":"a5ff2d9d-abac-5633-8929-e9bef8d72350","internal":{"content":"---\r\nexport const Title = () => (\r\n  <span>\r\n    Lab 3 - Performance Recommendations <br />\r\n  </span>\r\n);\r\n---\r\n\r\n## 3.1 - Analyze a container right-sizing performance recommendation\r\n\r\nLet’s explore one of the performance recommendations in more detail.\r\n\r\n#### Step 3.1.1\r\n - On the Action Details page, if the details are not already expanded, click Expand Details.\r\n\r\n![Lab3](images/3.1.1.jpg)\r\n\r\n#### Step 3.1.2\r\n - Review the performance action details. Point out the recommendation to upsize the virtual CPU limit from 200 mCores to 500 mCores.\r\n\r\n<InlineNotification>\r\nSince this is a dynamic system, the metrics displayed on your screen may not necessarily reflect the exact numbers in the screenshot.\r\n</InlineNotification>\r\n\r\n![Lab3](images/3.1.2.jpg)\r\n \r\nCPU throttling directly impacts the response time of a service and therefore user experience. Turbonomic observes and tracks CPU throttling. In the case of RobotShop, the response time latency of the payment service can adversely impact the ecommerce checkout experience.\r\nGiven the rate of throttling being observed, Turbonomic recommends increasing the CPU limit from 200 mCores to 500 mCores, thereby reducing the CPU throttling from 19.2% to 3.1%.\r\nProactively alleviating CPU congestion pressures by providing these analytics-driven recommendations helps keep the application in the desired state where it meets its defined service-level objectives (SLOs).\r\n\r\n#### Step 3.1.3\r\n - Click the X in the upper right corner to close the Action Details page.\r\n\r\n![Lab3](images/3.1.3.jpg)\r\n\r\n\r\n## 3.2 - Analyze a proactive workload redistribution recommendation\r\n\r\nThe underlying cloud native environment to which the RobotShop microservices are deployed is highly dynamic.\r\n\r\nThe initial node to which a pod was placed may not always remain the most optimal place to continue executing this workload. An unhealthy application can cause cascading issues, potentially impacting healthy neighboring pods. Additional node capacity may present alternative optimal placement options that were not available at the time when this pod was initially placed.\r\n\r\nContinuously and proactively redistributing workloads, in line with shifting load patterns and available capacity, helps assure application performance and infrastructure operational efficiency.\r\n\r\n#### Step 3.2.1\r\n - On the Action Center panel, under MOVE, select Container Pods (1). Then, click DETAILS (2) in the robot-shop/payment row.\r\n\r\n<InlineNotification>\r\n\r\n- Due to dynamic nature of the cluster, the MOVE option may not appear.  \r\n- If there are multiple robot-shop/payment rows, select the first one.\r\n\r\n</InlineNotification>\r\n\r\n![Lab3](images/3.2.1.jpg)\r\n\r\n#### Step 3.2.2\r\n - Review the efficiency action details. Point out the recommendation to relocate the payment pod from where it is currently running on worker node 3 to worker node 6.\r\n\r\n<InlineNotification>\r\nSince this is a dynamic system, the metrics displayed on your screen may not necessarily reflect the exact numbers in the screenshot.\r\n</InlineNotification>\r\n\r\n![Lab3](images/3.2.2.jpg)\r\n \r\nIf the underlying node is getting congested, it will attempt to identify an alternate node with more capacity. If, on the other hand, as is the case here, the underlying node is underutilized, it makes sense to proactively redistribute the workload to other appropriate nodes to improve operational efficiency.\r\n\r\nThe Turbonomic analysis engine computes the current and possible future state of the cluster if the Move action is accepted for execution. As we can observe here, the migration of workloads from worker node 3 to worker node 6 will result in a marginal increase of virtual CPU utilization from 7.1% to 10% and an increase of virtual memory consumption from 15.5% to 20.8% of worker node 6.\r\n\r\nContinuous redistribution of workloads helps better optimize overall cluster resources in terms of performance and cost of ownership.\r\n\r\n#### Step 3.2.3\r\n - Click the X in the upper right corner to close the Action Details page.\r\n\r\n![Lab3](images/3.2.3.jpg)\r\n\r\n## 3.3 - Analyze an intelligent cluster scaling recommendation\r\n\r\nThe Turbonomic analysis engine is continuously exploring opportunities to optimize overall cluster efficiency, essentially balancing cluster capacity with workload demand.\r\n\r\nPods consume resources from the underlying nodes on which they are placed. Nodes are represented as virtual machines (VMs) in the supply chain. When pods begin experiencing performance issues due to diminishing resources at the underlying node level, Turbonomic will provide early recommendations to provision additional cluster capacity.\r\n\r\nOn the other hand, it will seek out opportunities to consolidate workloads on a fewer number of nodes, thereby driving down operational costs.\r\n\r\n#### Step 3.3.1\r\n - On the Action Center panel, under SUSPEND, select Virtual Machines (1). Then, click DETAILS (2) in the vader.coc-ibm.com row.\r\n\r\n<InlineNotification>\r\nDue to dynamic nature of the cluster, the SUSPEND option may not appear. \r\n</InlineNotification>\r\n\r\n![Lab3](images/3.3.1.jpg)\r\n\r\n#### Step 3.3.2\r\n - Review the action details.\r\n\r\n![Lab3](images/3.3.2.jpg)\r\n\r\nExecuting the Suspend action will result in reclaiming and possibly repurposing the compute resources of worker node 3.\r\n\r\nThese actions enhance overall cluster operational efficiency and naturally yield significant costs savings, while not compromising application performance and availability.\r\n\r\n#### Step 3.3.3\r\n - Click the X in the upper right corner to close the Action Details page.","type":"Mdx","contentDigest":"b150f74fb25536c7c98ba38f92188544","owner":"gatsby-plugin-mdx","counter":233},"frontmatter":{"0":"e","1":"x","2":"p","3":"o","4":"r","5":"t","6":" ","7":"c","8":"o","9":"n","10":"s","11":"t","12":" ","13":"T","14":"i","15":"t","16":"l","17":"e","18":" ","19":"=","20":" ","21":"(","22":")","23":" ","24":"=","25":">","26":" ","27":"(","28":" ","29":"<","30":"s","31":"p","32":"a","33":"n","34":">","35":" ","36":"L","37":"a","38":"b","39":" ","40":"3","41":" ","42":"-","43":" ","44":"P","45":"e","46":"r","47":"f","48":"o","49":"r","50":"m","51":"a","52":"n","53":"c","54":"e","55":" ","56":"R","57":"e","58":"c","59":"o","60":"m","61":"m","62":"e","63":"n","64":"d","65":"a","66":"t","67":"i","68":"o","69":"n","70":"s","71":" ","72":"<","73":"b","74":"r","75":" ","76":"/","77":">","78":" ","79":"<","80":"/","81":"s","82":"p","83":"a","84":"n","85":">","86":" ","87":")","88":";","description":"Labs / Lab 3","title":"Labs / Lab 3"},"exports":{},"rawBody":"---\r\nexport const Title = () => (\r\n  <span>\r\n    Lab 3 - Performance Recommendations <br />\r\n  </span>\r\n);\r\n---\r\n\r\n## 3.1 - Analyze a container right-sizing performance recommendation\r\n\r\nLet’s explore one of the performance recommendations in more detail.\r\n\r\n#### Step 3.1.1\r\n - On the Action Details page, if the details are not already expanded, click Expand Details.\r\n\r\n![Lab3](images/3.1.1.jpg)\r\n\r\n#### Step 3.1.2\r\n - Review the performance action details. Point out the recommendation to upsize the virtual CPU limit from 200 mCores to 500 mCores.\r\n\r\n<InlineNotification>\r\nSince this is a dynamic system, the metrics displayed on your screen may not necessarily reflect the exact numbers in the screenshot.\r\n</InlineNotification>\r\n\r\n![Lab3](images/3.1.2.jpg)\r\n \r\nCPU throttling directly impacts the response time of a service and therefore user experience. Turbonomic observes and tracks CPU throttling. In the case of RobotShop, the response time latency of the payment service can adversely impact the ecommerce checkout experience.\r\nGiven the rate of throttling being observed, Turbonomic recommends increasing the CPU limit from 200 mCores to 500 mCores, thereby reducing the CPU throttling from 19.2% to 3.1%.\r\nProactively alleviating CPU congestion pressures by providing these analytics-driven recommendations helps keep the application in the desired state where it meets its defined service-level objectives (SLOs).\r\n\r\n#### Step 3.1.3\r\n - Click the X in the upper right corner to close the Action Details page.\r\n\r\n![Lab3](images/3.1.3.jpg)\r\n\r\n\r\n## 3.2 - Analyze a proactive workload redistribution recommendation\r\n\r\nThe underlying cloud native environment to which the RobotShop microservices are deployed is highly dynamic.\r\n\r\nThe initial node to which a pod was placed may not always remain the most optimal place to continue executing this workload. An unhealthy application can cause cascading issues, potentially impacting healthy neighboring pods. Additional node capacity may present alternative optimal placement options that were not available at the time when this pod was initially placed.\r\n\r\nContinuously and proactively redistributing workloads, in line with shifting load patterns and available capacity, helps assure application performance and infrastructure operational efficiency.\r\n\r\n#### Step 3.2.1\r\n - On the Action Center panel, under MOVE, select Container Pods (1). Then, click DETAILS (2) in the robot-shop/payment row.\r\n\r\n<InlineNotification>\r\n\r\n- Due to dynamic nature of the cluster, the MOVE option may not appear.  \r\n- If there are multiple robot-shop/payment rows, select the first one.\r\n\r\n</InlineNotification>\r\n\r\n![Lab3](images/3.2.1.jpg)\r\n\r\n#### Step 3.2.2\r\n - Review the efficiency action details. Point out the recommendation to relocate the payment pod from where it is currently running on worker node 3 to worker node 6.\r\n\r\n<InlineNotification>\r\nSince this is a dynamic system, the metrics displayed on your screen may not necessarily reflect the exact numbers in the screenshot.\r\n</InlineNotification>\r\n\r\n![Lab3](images/3.2.2.jpg)\r\n \r\nIf the underlying node is getting congested, it will attempt to identify an alternate node with more capacity. If, on the other hand, as is the case here, the underlying node is underutilized, it makes sense to proactively redistribute the workload to other appropriate nodes to improve operational efficiency.\r\n\r\nThe Turbonomic analysis engine computes the current and possible future state of the cluster if the Move action is accepted for execution. As we can observe here, the migration of workloads from worker node 3 to worker node 6 will result in a marginal increase of virtual CPU utilization from 7.1% to 10% and an increase of virtual memory consumption from 15.5% to 20.8% of worker node 6.\r\n\r\nContinuous redistribution of workloads helps better optimize overall cluster resources in terms of performance and cost of ownership.\r\n\r\n#### Step 3.2.3\r\n - Click the X in the upper right corner to close the Action Details page.\r\n\r\n![Lab3](images/3.2.3.jpg)\r\n\r\n## 3.3 - Analyze an intelligent cluster scaling recommendation\r\n\r\nThe Turbonomic analysis engine is continuously exploring opportunities to optimize overall cluster efficiency, essentially balancing cluster capacity with workload demand.\r\n\r\nPods consume resources from the underlying nodes on which they are placed. Nodes are represented as virtual machines (VMs) in the supply chain. When pods begin experiencing performance issues due to diminishing resources at the underlying node level, Turbonomic will provide early recommendations to provision additional cluster capacity.\r\n\r\nOn the other hand, it will seek out opportunities to consolidate workloads on a fewer number of nodes, thereby driving down operational costs.\r\n\r\n#### Step 3.3.1\r\n - On the Action Center panel, under SUSPEND, select Virtual Machines (1). Then, click DETAILS (2) in the vader.coc-ibm.com row.\r\n\r\n<InlineNotification>\r\nDue to dynamic nature of the cluster, the SUSPEND option may not appear. \r\n</InlineNotification>\r\n\r\n![Lab3](images/3.3.1.jpg)\r\n\r\n#### Step 3.3.2\r\n - Review the action details.\r\n\r\n![Lab3](images/3.3.2.jpg)\r\n\r\nExecuting the Suspend action will result in reclaiming and possibly repurposing the compute resources of worker node 3.\r\n\r\nThese actions enhance overall cluster operational efficiency and naturally yield significant costs savings, while not compromising application performance and availability.\r\n\r\n#### Step 3.3.3\r\n - Click the X in the upper right corner to close the Action Details page.","fileAbsolutePath":"C:/Users/905693897/github-doug/Turbonomic-1-Day-Partner-Workshop-2LABS - OLD/src/pages/Labs/Lab3.mdx"}}},
    "staticQueryHashes": ["1364590287","137577622","2102389209","2456312558","2746626797","3018647132","3037994772","768070550"]}